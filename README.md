# Fundametrics Stock Scraper

Production-grade web scraping system for Indian stock fundamental data from Screener.in and Moneycontrol.

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11 or higher
- MySQL 8.0+
- Git

### Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd fundametrics-scraper
```

2. **Create virtual environment**
```bash
# Windows
py -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment**
```bash
# Copy environment template
cp .env.example .env

# Edit .env with your database credentials
# nano .env  # or use your preferred editor
```

5. **Initialize database**
```bash
python scripts/init_db.py
```

6. **Run the scraper**
```bash
python main.py
```

## ğŸ“ Project Structure

```
fundametrics-scraper/
â”‚
â”œâ”€â”€ scraper/                    # Core scraping modules
â”‚   â”œâ”€â”€ sources/                # Source-specific scrapers
â”‚   â”‚   â”œâ”€â”€ screener.py         # Screener.in scraper
â”‚   â”‚   â””â”€â”€ moneycontrol.py     # Moneycontrol scraper
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                   # Core processing modules
â”‚   â”‚   â”œâ”€â”€ fetcher.py          # HTTP fetching logic
â”‚   â”‚   â”œâ”€â”€ parser.py           # HTML parsing
â”‚   â”‚   â”œâ”€â”€ cleaner.py          # Data cleaning
â”‚   â”‚   â””â”€â”€ validator.py        # Data validation
â”‚   â”‚
â”‚   â””â”€â”€ utils/                  # Utility modules
â”‚       â”œâ”€â”€ headers.py          # HTTP headers management
â”‚       â”œâ”€â”€ proxies.py          # Proxy rotation
â”‚       â”œâ”€â”€ rate_limiter.py     # Rate limiting
â”‚       â””â”€â”€ logger.py           # Logging utility
â”‚
â”œâ”€â”€ db/                         # Database modules
â”‚   â”œâ”€â”€ models.py               # SQLAlchemy models
â”‚   â””â”€â”€ migrate.py              # Migration scripts
â”‚
â”œâ”€â”€ config/                     # Configuration
â”‚   â””â”€â”€ settings.yaml           # Main configuration file
â”‚
â”œâ”€â”€ scheduler/                  # Job scheduling
â”‚   â””â”€â”€ cron.py                 # Scheduled jobs
â”‚
â”œâ”€â”€ logs/                       # Log files (auto-created)
â”œâ”€â”€ data/                       # Data storage (auto-created)
â”‚   â”œâ”€â”€ raw/                    # Raw HTML cache
â”‚   â”œâ”€â”€ processed/              # Processed data
â”‚   â””â”€â”€ backups/                # Database backups
â”‚
â”œâ”€â”€ .env                        # Environment variables (create from .env.example)
â”œâ”€â”€ .env.example                # Environment template
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ main.py                     # Application entry point
```

## âš™ï¸ Configuration

All configuration is managed through `config/settings.yaml`. Key settings:

- **Scrapers**: Rate limits, timeouts, endpoints
- **Database**: Connection settings, pool configuration
- **Scheduler**: Scraping schedule (default: 6 PM IST daily)
- **Logging**: Log levels, rotation, retention
- **Monitoring**: Prometheus metrics, alerts

Environment-specific values (passwords, secrets) should be set in `.env` file.

## ğŸ”§ Usage

### Manual Scraping
```bash
# Scrape specific stock
python scripts/manual_scrape.py --symbol RELIANCE

# Scrape multiple stocks
python scripts/manual_scrape.py --symbols RELIANCE,TCS,INFY

# Scrape all stocks
python scripts/manual_scrape.py --all
```

### Scheduled Scraping
```bash
# Start scheduler (runs daily at 6 PM IST)
python main.py --mode scheduler
```

### API Server
```bash
# Start API server
python main.py --mode api

# API will be available at http://localhost:8000
# API docs at http://localhost:8000/docs
```

## ğŸ“Š API Endpoints

- `GET /api/v1/stocks/{symbol}/fundamentals` - Get fundamental data
- `GET /api/v1/stocks/{symbol}/financials` - Get financial statements
- `GET /api/v1/stocks/search` - Search stocks
- `GET /api/v1/scraper/status` - Get scraper status
- `POST /api/v1/scraper/trigger` - Trigger manual scrape (admin)

## ğŸ›¡ï¸ Anti-Ban Measures

- **Rate limiting**: 10 req/min for Screener.in, 15 req/min for Moneycontrol
- **User-agent rotation**: Rotates through realistic browser user-agents
- **Random delays**: 6Â±2 seconds between requests
- **Retry logic**: Exponential backoff on failures
- **Session management**: Persistent sessions with cookie handling
- **Respectful scraping**: Off-peak hours, minimal server load

## ğŸ”„ Failure Recovery

- **Checkpoints**: Resume from last successful point
- **Retry queue**: Failed requests automatically retried
- **Data versioning**: Keep last 7 versions, rollback capability
- **Circuit breaker**: Auto-stop if error rate > 20%
- **Graceful degradation**: Use cached data if scraping fails

## ğŸ“ˆ Monitoring

- **Prometheus metrics** on port 9090
- **Health checks** every 60 seconds
- **Email/Slack alerts** for failures
- **Success rate tracking** (target: >95%)

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=scraper

# Run specific test
pytest tests/unit/test_scrapers.py
```

## ğŸ“ Logging

Logs are stored in `logs/` directory:
- `fundametrics-scraper.log` - All logs (rotated at 500MB)
- `errors.log` - Error logs only (rotated at 100MB)

Log retention: 30 days for general logs, 90 days for errors.

## ğŸš¢ Deployment

### Docker
```bash
# Build image
docker build -t fundametrics-scraper .

# Run with docker-compose
docker-compose up -d
```

### Production Checklist
- [ ] Set `APP_ENV=production` in `.env`
- [ ] Set `DEBUG=false` in `.env`
- [ ] Configure strong database password
- [ ] Enable HTTPS for API
- [ ] Set up database backups
- [ ] Configure monitoring alerts
- [ ] Review rate limits
- [ ] Test failure recovery

## ğŸ“„ License

Proprietary - Fundametrics

## ğŸ¤ Contributing

Internal project - contact the development team for contribution guidelines.

## âš ï¸ Legal Notice

This scraper is designed to:
- Scrape only publicly available data
- Respect robots.txt
- Minimize server load
- Comply with website terms of service
- Follow India's IT Act, 2000

**Use responsibly and ethically.**

## ğŸ“ Support

For issues or questions, contact: dev@fundametrics.com
